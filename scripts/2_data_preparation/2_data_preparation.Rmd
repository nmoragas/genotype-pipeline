---
title: "Imputation Pipeline: 2_DATA PREPARATION"
output: html_document
date: "`r Sys.Date()`"
params:
  dataDir:
    label: "dataDir"
    value: ""
  refDir:
    label: "refDir:"
    value: ""
  plinkFile:
    label: "plinkFile:"
    value: ""
  assembly:
    label: "assembly:"
    value: ""
---

This script prepares genotype data for imputation using the TOPMed reference panel. It performs the following steps:

a) Removes invalid SNPs
b) Performs LiftOver from genome build GRCh37 (hg19) to GRCh38 (hg38)
c) Checks and validates the BIM file
d) Creates a sorted and compressed .vcf.gz file

The LiftOver and BIM check steps require several external files. Instructions for downloading these required resources are included in the script.



```{r setup, include=FALSE}

library(knitr)


# TO MODIFY:
setwd("./2_data_preparation")

dataDir <-"./1_QC/QC/"

# data result from /QC
plinkFile <- "_______filtered_QC"

#dir.create("./Data2Impute/",showWarnings=FALSE)
outputDir<-"./Data2Impute/"

# Read bim
bim <- read.table(paste0(dataDir, plinkFile, ".bim"), header = FALSE, stringsAsFactors = FALSE, sep = "\t")

# original genoma
assembly <- "hg19"

# bimchek reference panel (to download). 
refDir <- "./TOPMed/"      #"/mnt/typhon/references/SNPs/TOPMed/"
```

<br>
Data must be prepared to upload to the TopMed Imputation Server.
<br>

### Requisites:

------ Programs ------

* R 3.5

* plink 1.9

* vcftools-0.1.16

* python-2.7.15

* bcftools-1.9

* perl-5.26.2

------ Data ------

* Data must be in plink format (bed + bim + fam)



------ liftover ------

<https://github.com/sritchie73/liftOverPlink/blob/master/liftOverPlink.py>

* liftover/liftOverPlink.py 
* liftover/liftOver   you will need to download this file from http://hgdownload.cse.ucsc.edu/admin/exe/  [linux.x86_64/]
* liftover/hg19ToHg38.over.chain.gz if assemby is hg19  https://hgdownload.soe.ucsc.edu/gbdb/hg19/liftOver/

```{r}
dir.create("./liftover/",showWarnings=FALSE)


```


------ bim check ------

<https://www.well.ox.ac.uk/-wrayner/tools/> o <https://www.chg.ox.ac.uk/~wrayner/tools/>

* bimcheck/HRC-1000G-check-bim.pl -v4.3.0 de:
https://www.chg.ox.ac.uk/~wrayner/tools/
* bimcheck/CreateTOPMed.pl
* PASS.Variants.TOPMed_freeze5_hg38_dbSNP.tab in refDir

To obtain PASS.Variants.TOPMed_freeze5_hg38_dbSNP.tab file:

1.- Download it
system("curl 'https://bravo.sph.umich.edu/freeze5/hg38/download/all' -H 'Accept-Encoding: gzip, deflate, br' -H --compressed > ALL.TOPMed_freeze5_hg38_dbSNP.vcf.gz")
2.- Once downloaded the VCF can be converted to an HRC formatted reference legend using the code here: CreateTOPMed.zip
system("perl ./CreateTOPMed.pl -i ALL.TOPMed_freeze5_hg38_dbSNP.vcf.gz")
!!! 10 hours of execution!!!



```{r}
dir.create("./bimcheck/",showWarnings=FALSE)

# 1 download
system("curl 'https://bravo.sph.umich.edu/freeze5/hg38/download/all' -H 'Accept-Encoding: gzip, deflate, br' -H --compressed > ALL.TOPMed_freeze5_hg38_dbSNP.vcf.gz") # pot Manual Download Instructions:  https://bravo.sph.umich.edu/freeze5/hg38/download/all 

https://bravo.sph.umich.edu/freeze10/hg38/download/all
# 2.- Once downloaded the VCF can be converted to an HRC formatted reference legend using the code here: CreateTOPMed.zip
# system("perl ./bimcheck/CreateTOPMed.pl -i ./bimcheck/ALL.TOPMed_freeze5_hg38_dbSNP.vcf.gz")

# VCF conversion to HRC
qsub vcf_conversion_to_HRC.qsub
```



<br>  

```{r, eval=TRUE, echo=FALSE, warning=FALSE, results='asis', error=FALSE}

cat("\n")
cat(paste0("Data preparation for ",dataDir,plinkFile," data."))
cat("\n")

fam <- read.table(paste0(dataDir, plinkFile, ".fam") ,stringsAsFactors = FALSE, header = FALSE, sep = "")

cat("\n")
cat(paste0("There are ",nrow(fam)," samples in ",plinkFile," data."))
cat("\n")

cat("\n")
cat(paste0("There are ",nrow(bim)," SNPs in ",plinkFile," data."))
cat("\n")


```

### a) Remove non valid SNPs

```{r, eval=TRUE, echo=FALSE, warning=FALSE, results='asis', error=FALSE}

cat("\n")
cat("* Filter SNPs in autosomal or X chromosome")
cat("\n")

chrom <- c(seq(1,23),"X")
bim <- bim[bim$V1%in%chrom,]

cat("\n")
cat("* Filter SNPs with A, T, C or G alleles")
cat("\n")

bim <- bim[bim$V5%in%c("A","C","T","G") & bim$V6%in%c("A","C","T","G"),]

cat("\n")
cat("* Remove multiple mapping SNPs")
cat("\n")

sp <- bim[,c(1, 4)]
sp <- sp$pos[duplicated(sp)]
if(length(sp)>0) bim <- bim[!bim$pos%in%sp,]

write.table(bim$V2, paste0(dataDir, "ValidSNPs.txt"), sep = "\t", quote = FALSE, col.names = FALSE, row.names = FALSE)

# Filter in valid SNPs
cat("\n")
cat("* Filter SNPs with MAF>0.00001")
cat("\n")
system(paste0("plink --bfile ", dataDir, plinkFile, " --extract ", dataDir, "ValidSNPs.txt --maf 0.00001 --recode --output-chr M --out liftover/", plinkFile))




# remove some files
unlink(paste0("liftover/",plinkFile,".log"))
unlink(paste0(dataDir,"ValidSNPs.txt"))

bim <- read.table(paste0("liftover/", plinkFile, ".map"), header = FALSE, stringsAsFactors = FALSE, sep = "\t")
cat("\n")
cat(paste0("After removing non valid SNPs, ",nrow(bim)," SNPs remained."))
cat("\n")

```

<br>

### b) LiftOver:

```{r, eval=TRUE, echo=FALSE, warning=FALSE, results='asis', error=FALSE}

cat("\n")
cat(paste0("Transform data from ",assembly," to hg38."))
cat("\n")

system(paste0("chmod 755 liftover/liftOverPlink.py"))
system(paste0("chmod 755 liftover/liftOver"))
system(paste0("python2 liftover/liftOverPlink.py -m liftover/", plinkFile,".map -p liftover/", plinkFile,".ped -o liftover/", plinkFile,"_liftover -c liftover/",assembly,"ToHg38.over.chain.gz -e liftover/liftOver"))

unlink(paste0("liftover/", plinkFile,".ped"))
unlink(paste0("liftover/", plinkFile,".map"))


bim<-read.table(paste0("liftover/", plinkFile,"_liftover.map"), header = FALSE, stringsAsFactors = FALSE, sep = "\t")
chrom <- c(seq(1,23),"X")
bim <- bim[bim$V1%in%chrom,]

write.table(bim$V2, paste0("liftover/ValidSNPs.txt"), sep = "\t", quote = FALSE, col.names = FALSE, row.names = FALSE)

cat("\n")
cat(paste0("After liftover, ",nrow(bim)," SNPs remained."))
cat("\n")

```


<br>

### c) Check bim
https://www.well.ox.ac.uk/-wrayner/tools/

This program produces a file called Run-plink.sh with different plink orders to match data to refrence


See: https://genepi.github.io/michigan-imputationserver/prepare-your-data/


```{r, eval=TRUE, echo=FALSE, warning=FALSE, results='asis', error=FALSE}

# 1 Transform ped/map to bim/bed/fam

# plink --make-bed


cat("\n")
cat("* Transform ped/map to bim/bed/fam")
cat("\n")


system(paste0("plink --file liftover/", plinkFile,"_liftover  --extract liftover/ValidSNPs.txt --allow-extra-chr --make-bed --out bimcheck/", plinkFile))

# remove some files
#unlink(paste0("liftover/ValidSNPs.txt"))

```


```{r, eval=TRUE, echo=FALSE, warning=FALSE, results='asis', error=FALSE}

# 2 Create a frequency file

cat("\n")
cat("* Allele frequency calculation")
cat("\n")


# --freq calcula la freqüència al·lèlica per cada SNP
system(paste0("plink --bfile bimcheck/", plinkFile," --freq --out bimcheck/", plinkFile))

# genera un arxiu .frq

unlink(paste0("bimcheck/", plinkFile,".log"))

```





```{r, eval=TRUE, echo=FALSE, warning=FALSE, results='asis', error=FALSE}

# 3 Execute script:

cat("\n")
cat("* Check bim file")
cat("\n")

# * refDir: directory with ALL.TOPMed_freeze5_hg38_dbSNP.vcf.gz file

#File Permission Setup
#The following command sets the appropriate permissions for the script HRC-1000G-check-bim.pl located in the bimcheck directory:
system(paste0("chmod 755 bimcheck/HRC-1000G-check-bim.pl"))

# Verify and correct the .bim file using a reference panel.
## -r referencia
## -p EUR -> població EURopea
## -c automatic correction
system(paste0("perl bimcheck/HRC-1000G-check-bim.pl -b bimcheck/",plinkFile,".bim -f bimcheck/",plinkFile,".frq -r ", refDir, "/PASS.Variants.TOPMed_freeze5_hg38_dbSNP.tab.gz -h -o bimcheck/"))


# This script will generate a file with the variants that need to be corrected or filtered.
cat("\n")
cat("* run Run.sh")
cat("\n")
# system(paste0("chmod 755 bimcheck/Run-plink.sh"))
# system(paste0("bimcheck/Run-plink.sh"))
system("sh bimcheck/Run-plink.sh")

unlink("bimcheck/TEMP*")

```


## d) Crear vcf files

```{bash}
# Create output directory if it doesn't exist
mkdir -p Data2Impute


# 4 Create VCF Files with Correct Chromosome Naming

# Although normally VCF files are generated from PLINK files using:
#plink --bfile <prefix_bim_file> --recode vcf-iid --out <output-vcf>

#his step is not necessary here because the script Run-plink.sh already generates VCFs. However, the chromosome names in those files are numeric (e.g., 1) and need to be #converted to the chr1 format to comply with reference genome conventions.

#To automate this renaming using bcftools and avoid hardcoding file names, we define the PLINK file prefix as a variable and apply the conversion dynamically:
```



```{r}
# els vcf tnene eles cromosomes anometats com ex. 1. hi ha de ser chr1. Modificar:

# Loop through chromosomes 1 to 22
for i in {1..22}; do
  bcftools annotate \
    --rename-chrs <(awk '{print $1, "chr"$1}' bimcheck/${plinkFile}-updated-chr${i}.vcf | grep -v "^#") \
    bimcheck/${plinkFile}-updated-chr${i}.vcf \
    > Data2Impute/${plinkFile}_chr${i}.vcf
done

# Rename chromosome 23 to chrX
bcftools annotate \
  --rename-chrs <(echo -e "23\tchrX") \
  bimcheck/${plinkFile}-updated-chr23.vcf \
  -o Data2Impute/${plinkFile}_chrX.vcf
```


## e) Create sorted .vcf.gz file

```{r}

# * Create a sorted *.vcf.gz file 

# Sort and compress autosomal chromosomes (1–22)
for i in {1..22}; do 
  bcftools sort ${outputDir}/${plinkFile}_chr${i}.vcf -Oz \
    -o ${outputDir}/${plinkFile}_chr${i}.vcf.gz
done

# Sort and compress chromosome X
bcftools sort ${outputDir}/${plinkFile}_chrX.vcf -Oz \
  -o ${outputDir}/${plinkFile}_chrX.vcf.gz
```


<br>


#### Output files:

The output files of the Data Preparation are:

* Results of the liftover (map and ped files) and a file with the unlifted SNPs (unlifted).

* Results of the bimcheck analysis in the bimcheck folder: Different files with lists of SNPs that have been modified and plinks files for each chormosome (bed, bim and fam).

* vcf.gz and vcf.gz.csi for each chromosome (autosomes and chrX) in the Data2Impute folder. This files are the ones to be uploaded to TopMed Imputation Server.
